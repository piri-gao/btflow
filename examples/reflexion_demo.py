"""
Reflexion Agent Demo - Self-Refine æ¨¡å¼ï¼ˆOpenAI å…¼å®¹ APIï¼‰

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ btflow çš„ Reflexion æ¨¡å¼è¿­ä»£æ”¹è¿›è¾“å‡ºè´¨é‡ã€‚

æµç¨‹ï¼š
    1. ç”Ÿæˆåˆå§‹ç­”æ¡ˆ
    2. è‡ªæˆ‘è¯„ä¼° (0-10 åˆ†)
    3. å¦‚æœåˆ†æ•° < é˜ˆå€¼ï¼Œåæ€å¹¶æ”¹è¿›
    4. é‡å¤ç›´åˆ°è¾¾æ ‡æˆ–è¾¾åˆ°æœ€å¤§è½®æ•°

è¿è¡Œæ–¹å¼ï¼š
    export OPENAI_API_KEY="your-api-key"
    export BASE_URL="https://your-openai-compatible-endpoint"
    python examples/reflexion_demo.py
"""
import asyncio
import os
import sys
from dotenv import load_dotenv

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
load_dotenv()

from btflow.patterns.reflexion import ReflexionAgent
from btflow.llm import LLMProvider


async def demo_haiku(provider):
    """æ¼”ç¤ºï¼šç”Ÿæˆè¯—æ­Œ"""
    print("\n" + "="*60)
    print("ğŸ“ Demo: Generate a Haiku")
    print("="*60 + "\n")
    
    agent = ReflexionAgent.create(
        provider=provider,
        model="gemini-2.5-flash",
        threshold=8.0,   # åˆ†æ•°é˜ˆå€¼
        max_rounds=3     # æœ€å¤§æ”¹è¿›è½®æ•°
    )
    
    task = "Write a haiku about coding at midnight"
    print(f"ğŸ“‹ Task: {task}\n")
    
    result = await agent.run(
        input_data={"task": task},
        max_ticks=50
    )
    
    state = agent.state_manager.get()
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Final Status: {result}")
    print(f"ğŸ’¬ Final Answer:\n{state.answer}")
    print(f"â­ Final Score: {state.score:.1f}")
    print(f"ğŸ”„ Total Rounds: {state.round}")
    
    if len(state.score_history) > 1:
        print(f"\nğŸ“ˆ Score Progress: {' â†’ '.join(f'{s:.1f}' for s in state.score_history)}")


async def demo_explanation(provider):
    """æ¼”ç¤ºï¼šç”Ÿæˆè§£é‡Š"""
    print("\n" + "="*60)
    print("ğŸ§  Demo: Explain a Concept")
    print("="*60 + "\n")
    
    agent = ReflexionAgent.create(
        provider=provider,
        model="gemini-2.5-flash",
        threshold=9.8,   # æé«˜é˜ˆå€¼ï¼Œå¼ºåˆ¶å¤šè½®æ”¹è¿›
        max_rounds=5     # å…è®¸æ›´å¤šæ”¹è¿›
    )
    
    task = "Explain quantum computing to a 10-year-old in 3 sentences"
    print(f"ğŸ“‹ Task: {task}\n")
    
    result = await agent.run(
        input_data={"task": task},
        max_ticks=50
    )
    
    state = agent.state_manager.get()
    print(f"\n{'='*60}")
    print(f"ğŸ’¬ Final Answer:\n{state.answer}")
    print(f"â­ Final Score: {state.score:.1f}")
    print(f"ğŸ”„ Total Rounds: {state.round}")
    
    if len(state.answer_history) > 1:
        print(f"\nğŸ“œ Improvement History:")
        for i, (ans, score) in enumerate(zip(state.answer_history, state.score_history)):
            print(f"  Round {i+1} (Score: {score:.1f}):")
            print(f"    Answer: {ans[:80]}..." if len(ans) > 80 else f"    Answer: {ans}")
            if i < len(state.reflection_history):
                ref = state.reflection_history[i]
                if ref:
                    print(f"    Reflection: {ref[:80]}..." if len(ref) > 80 else f"    Reflection: {ref}")


async def main():
    """è¿è¡Œæ¼”ç¤º"""
    base_url = os.getenv("BASE_URL")

    try:
        # Prefer Gemini to avoid key mismatch issues
        provider = LLMProvider.default(preference=["gemini", "openai"], base_url=base_url)
    except RuntimeError as e:
        print(str(e))
        return
    
    print("ğŸ”„ BTflow Reflexion Agent Demo (Self-Refine)")
    print("=" * 60)
    await demo_haiku(provider)


if __name__ == "__main__":
    asyncio.run(main())
