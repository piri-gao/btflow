"""
RL Step æ¨¡å¼æ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ BTAgent.step() è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ

æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„é¿éšœåœºæ™¯ï¼š
- è§‚æµ‹: {"obstacle": bool, "distance": float}
- åŠ¨ä½œ: speed, turn
"""
import sys
import os
import asyncio
from typing import Annotated, List
from pydantic import BaseModel, Field

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# ç»Ÿä¸€ import
from btflow import BTAgent, StateManager, ActionField, Behaviour, Status


# === 1. å®šä¹‰ State Schema ===
class RLAgentState(BaseModel):
    # è§‚æµ‹æ•°æ®ï¼ˆæ¯å¸§æ›´æ–°ï¼‰
    obstacle_detected: bool = False
    obstacle_distance: float = 100.0
    
    # åŠ¨ä½œè¾“å‡ºï¼ˆActionField æ¯å¸§è‡ªåŠ¨é‡ç½®ï¼‰
    speed: Annotated[float, ActionField()] = 0.0
    turn: Annotated[float, ActionField()] = 0.0


# === 2. å®šä¹‰åŒæ­¥è¡Œä¸ºèŠ‚ç‚¹ï¼ˆè‚Œè‚‰èŠ‚ç‚¹ï¼‰ ===
class ObstacleAvoidanceNode(Behaviour):
    """
    ç®€å•çš„é¿éšœé€»è¾‘ï¼ˆåŒæ­¥èŠ‚ç‚¹ï¼Œç«‹å³è¿”å›ï¼‰
    """
    def __init__(self, name: str):
        super().__init__(name)
        self.state_manager: StateManager = None
    
    def update(self) -> Status:
        state = self.state_manager.get()
        
        # æ ¹æ®è§‚æµ‹å†³ç­–åŠ¨ä½œ
        if state.obstacle_detected:
            if state.obstacle_distance < 10:
                # ç´§æ€¥è½¬å‘
                self.state_manager.update({"speed": 0.2, "turn": 0.8})
            else:
                # å‡é€Ÿè½¬å‘
                self.state_manager.update({"speed": 0.5, "turn": 0.3})
        else:
            # æ— éšœç¢ï¼Œå…¨é€Ÿå‰è¿›
            self.state_manager.update({"speed": 1.0, "turn": 0.0})
        
        return Status.SUCCESS


# === æ¨¡æ‹Ÿç¯å¢ƒ ===
class SimpleEnv:
    """ç®€å•çš„æ¨¡æ‹Ÿç¯å¢ƒ"""
    def __init__(self):
        self.step_count = 0
        self.obstacle_pos = 20  # éšœç¢ç‰©ä½ç½®
        self.agent_pos = 0
    
    def reset(self):
        self.step_count = 0
        self.agent_pos = 0
        return self._get_obs()
    
    def step(self, action: dict):
        # æ‰§è¡ŒåŠ¨ä½œ
        speed = action.get("speed", 0)
        turn = action.get("turn", 0)
        
        # ç®€å•æ¨¡æ‹Ÿï¼šå‰è¿› + è½¬å‘ä¼šé¿å¼€éšœç¢
        if turn > 0.5:
            self.agent_pos += speed  # è½¬å‘æ—¶éšœç¢ç‰©ç›¸å¯¹è·ç¦»ä¸å˜
        else:
            self.agent_pos += speed
        
        self.step_count += 1
        
        # è®¡ç®—å¥–åŠ±
        distance = self.obstacle_pos - self.agent_pos
        if distance < 5 and turn < 0.5:
            reward = -10  # ç¢°æ’
            done = True
        elif self.agent_pos > 30:
            reward = 10  # æˆåŠŸé€šè¿‡
            done = True
        else:
            reward = 0.1  # å­˜æ´»å¥–åŠ±
            done = self.step_count >= 50
        
        return self._get_obs(), reward, done, {}
    
    def _get_obs(self):
        distance = max(0, self.obstacle_pos - self.agent_pos)
        return {
            "obstacle_detected": distance < 30,
            "obstacle_distance": distance
        }


async def main():
    print("=" * 50)
    print("ğŸ® RL Step æ¨¡å¼æ¼”ç¤º")
    print("=" * 50)
    
    # === åˆå§‹åŒ– ===
    state_manager = StateManager(schema=RLAgentState)
    state_manager.initialize()
    
    # æ„å»ºè¡Œä¸ºæ ‘
    root = ObstacleAvoidanceNode("AvoidObstacle")
    agent = BTAgent(root, state_manager)
    
    # åˆ›å»ºç¯å¢ƒ
    env = SimpleEnv()
    
    # === è®­ç»ƒå¾ªç¯ ===
    num_episodes = 3
    
    for episode in range(num_episodes):
        print(f"\n--- Episode {episode + 1} ---")
        
        # Episode å¼€å§‹ï¼šé‡ç½®
        obs = env.reset()
        agent.reset(reset_data=True)  # æ¸…ç©ºçŠ¶æ€
        
        total_reward = 0
        done = False
        frame = 0
        
        while not done:
            # ä½¿ç”¨ step() æ¨¡å¼ï¼šæ³¨å…¥è§‚æµ‹ â†’ tick â†’ è·å–åŠ¨ä½œ
            action = await agent.step(obs)
            
            # æ‰“å°å…³é”®å¸§
            if frame % 10 == 0 or obs["obstacle_distance"] < 15:
                print(f"  Frame {frame}: obs={obs}, action={action}")
            
            # ç¯å¢ƒæ­¥è¿›
            obs, reward, done, _ = env.step(action)
            total_reward += reward
            frame += 1
        
        print(f"  Episode {episode + 1} ç»“æŸ: total_reward={total_reward:.2f}, frames={frame}")
    
    print("\n" + "=" * 50)
    print("âœ… RL Step æ¨¡å¼æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 50)


if __name__ == "__main__":
    asyncio.run(main())
